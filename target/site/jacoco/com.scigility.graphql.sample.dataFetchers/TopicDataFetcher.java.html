<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>TopicDataFetcher.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">graphql-spring-boot-starter-sample</a> &gt; <a href="index.source.html" class="el_package">com.scigility.graphql.sample.dataFetchers</a> &gt; <span class="el_source">TopicDataFetcher.java</span></div><h1>TopicDataFetcher.java</h1><pre class="source lang-java linenums">package com.scigility.graphql.sample.dataFetchers;

import com.scigility.graphql.sample.domain.TableRecord;
import com.scigility.graphql.sample.domain.Topic;
import com.scigility.graphql.sample.domain.TopicRecord;
import com.scigility.graphql.sample.domain.Kafka;
import org.apache.avro.Schema;
import lombok.val;

import com.merapar.graphql.base.TypedValueMap;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.ByteArrayDeserializer;
import org.apache.kafka.common.serialization.ByteArraySerializer;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KStreamBuilder;
import org.apache.kafka.streams.kstream.KTable;
import org.apache.kafka.streams.state.KeyValueIterator;
import org.apache.kafka.streams.state.QueryableStoreTypes;
import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;
import org.springframework.stereotype.Component;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.avro.generic.GenericData;
import org.apache.avro.generic.GenericRecord;
import com.twitter.bijection.Injection;
import com.twitter.bijection.avro.GenericAvroCodecs;

import java.util.*;
import java.util.concurrent.TimeUnit;

import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.serialization.StringDeserializer;

import kafka.admin.AdminUtils;
import kafka.utils.ZKStringSerializer$;
import kafka.admin.RackAwareMode;
import kafka.utils.ZkUtils;

import org.I0Itec.zkclient.ZkClient;
import org.I0Itec.zkclient.ZkConnection;

import org.apache.zookeeper.ZooKeeper;

@Component
<span class="fc" id="L55">public class TopicDataFetcher {</span>
<span class="fc" id="L56">    private Log log = LogFactory.getLog(TopicDataFetcher.class);</span>

<span class="fc" id="L58">    public Map&lt;String,Topic&gt; topics = new HashMap&lt;&gt;();</span>

    private KafkaStreams streams;

    public List&lt;Topic&gt; getTopicsByFilter(TypedValueMap arguments) {
<span class="nc" id="L63">        val kafka = Kafka.getInstance();</span>

<span class="nc" id="L65">        log.info(&quot;getTopicsByFilter&quot;);</span>

<span class="nc" id="L67">        ZkClient zkClient = null;</span>
<span class="nc" id="L68">        ZkUtils zkUtils = null;</span>
<span class="nc" id="L69">        int sessionTimeOutInMs = 20 * 1000; // 15 secs</span>
<span class="nc" id="L70">        int connectionTimeOutInMs = 20 * 1000; // 10 secs</span>
<span class="nc" id="L71">        boolean isSecureKafkaCluster = false;</span>

        try {
<span class="nc" id="L74">            ZooKeeper zk = new ZooKeeper(</span>
<span class="nc" id="L75">                    kafka.getZookeeper(), sessionTimeOutInMs, null);</span>

<span class="nc" id="L77">            List&lt;String&gt; _topics = zk.getChildren(</span>
                    &quot;/brokers/topics&quot;, false);

            try{
<span class="nc" id="L81">                TimeUnit.MILLISECONDS.sleep((long)(sessionTimeOutInMs*0.1));</span>
<span class="nc" id="L82">            } catch (java.lang.InterruptedException e){}</span>

<span class="nc" id="L84">            log.info(&quot;List of Topics&quot;);</span>
<span class="nc" id="L85">            int index = 0;</span>
<span class="nc bnc" id="L86" title="All 2 branches missed.">            for (String topicName : _topics) {</span>
<span class="nc" id="L87">                log.info(&quot;topicName:&quot;+topicName);</span>

<span class="nc bnc" id="L89" title="All 2 branches missed.">                if ( !topics.containsKey(topicName) ) {</span>
<span class="nc" id="L90">                    val topic = new Topic();</span>
<span class="nc" id="L91">                    topic.setName(topicName);</span>
<span class="nc" id="L92">                    topics.put(topicName,topic);</span>
                }
<span class="nc" id="L94">            }</span>
<span class="nc" id="L95">        } catch (Exception ex) {</span>
<span class="nc" id="L96">            ex.printStackTrace();</span>
        } finally {
<span class="nc bnc" id="L98" title="All 6 branches missed.">            if (zkClient != null) {</span>
<span class="nc" id="L99">                zkClient.close();</span>
            }
        }

<span class="nc" id="L103">        return new ArrayList&lt;Topic&gt;(topics.values());</span>
    }

    public String addTopic(TypedValueMap arguments) {
<span class="nc" id="L107">        log.info(&quot;addTopic&quot;);</span>
<span class="nc" id="L108">        String result = &quot;&quot;;</span>
<span class="nc" id="L109">        ZkClient zkClient = null;</span>
<span class="nc" id="L110">        ZkUtils zkUtils = null;</span>
<span class="nc" id="L111">        val kafka = Kafka.getInstance();</span>

<span class="nc" id="L113">        LinkedHashMap schema = arguments.get(&quot;schema&quot;);</span>
<span class="nc" id="L114">        log.info(&quot;schema:&quot;+schema.toString());</span>

<span class="nc" id="L116">        String topicName = arguments.get(&quot;name&quot;);</span>
<span class="nc" id="L117">        log.info(&quot;topicName=&quot;+topicName);</span>
<span class="nc" id="L118">        int noOfPartitions = 1;</span>
<span class="nc" id="L119">        int noOfReplication = 1;</span>

        try {
<span class="nc" id="L122">            log.info(&quot;zookeeperHosts=&quot;+kafka.getZookeeper());</span>
<span class="nc" id="L123">            zkClient = new ZkClient(</span>
<span class="nc" id="L124">                    kafka.getZookeeper(),</span>
                    20 * 1000,
                    20 * 1000,
                    ZKStringSerializer$.MODULE$);

<span class="nc" id="L129">            zkUtils = new ZkUtils(zkClient, new ZkConnection(</span>
<span class="nc" id="L130">                    kafka.getZookeeper()), false);</span>

<span class="nc" id="L132">            Properties topicConfiguration = new Properties();</span>

<span class="nc" id="L134">            log.info(&quot;AdminUtils.createTopic&quot;);</span>
<span class="nc" id="L135">            AdminUtils.createTopic(zkUtils,</span>
                    topicName, noOfPartitions, noOfReplication, topicConfiguration,
                    RackAwareMode.Safe$.MODULE$);

<span class="nc" id="L139">            log.info(&quot;AdminUtils.wait the result&quot;);</span>
            try{
<span class="nc" id="L141">                TimeUnit.MILLISECONDS.sleep((long)(1000));</span>
<span class="nc" id="L142">            } catch (java.lang.InterruptedException e){}</span>

<span class="nc" id="L144">        } catch (Exception ex) {</span>
<span class="nc" id="L145">            log.error(&quot;error:&quot;+ex.getMessage());</span>
<span class="nc" id="L146">            result = ex.getMessage();</span>
<span class="nc" id="L147">            ex.printStackTrace();</span>
        } finally {
<span class="nc bnc" id="L149" title="All 6 branches missed.">            if (zkClient != null) {</span>
<span class="nc" id="L150">                zkClient.close();</span>
            }
<span class="nc bnc" id="L152" title="All 6 branches missed.">            if ( !topics.containsKey(topicName) ) {</span>
<span class="nc" id="L153">                val topic = new Topic();</span>
<span class="nc" id="L154">                topic.setName(topicName);</span>
<span class="nc" id="L155">                topic.setSchema(readSchema(schema));</span>
<span class="nc" id="L156">                topics.put(topicName,topic);</span>
<span class="nc" id="L157">                result = &quot;topic &quot;+topicName+&quot; created&quot;;</span>
<span class="nc" id="L158">            } else {</span>
<span class="nc" id="L159">                val topic = topics.get(topicName);</span>
<span class="nc" id="L160">                topic.setSchema(readSchema(schema));</span>
<span class="nc" id="L161">                topics.put(topicName,topic);</span>
<span class="nc" id="L162">                result = &quot;topic &quot;+topicName+&quot; updated&quot;;</span>
<span class="nc" id="L163">            }</span>
<span class="nc" id="L164">        }</span>
<span class="nc" id="L165">        return result;</span>
    }

    public String produceTopicRecord(TypedValueMap arguments) {
<span class="nc" id="L169">        log.info(&quot;produceTopicRecord&quot;);</span>
<span class="nc" id="L170">        String result = &quot;&quot;;</span>
<span class="nc" id="L171">        val kafka = Kafka.getInstance();</span>

<span class="nc" id="L173">        String name = arguments.get(&quot;name&quot;);</span>
<span class="nc" id="L174">        log.info(&quot;name:&quot;+name);</span>
<span class="nc" id="L175">        val topic = topics.get(name);</span>

<span class="nc" id="L177">        LinkedHashMap record = arguments.get(&quot;record&quot;);</span>
<span class="nc" id="L178">        String customer = (String)record.get(&quot;customer&quot;);</span>
<span class="nc" id="L179">        Integer income = (Integer)record.get(&quot;income&quot;);</span>
<span class="nc" id="L180">        Integer expenses = (Integer)record.get(&quot;expenses&quot;);</span>
<span class="nc" id="L181">        log.info(&quot;constumer:&quot;+customer+&quot;,income:&quot;+income+&quot;,expenses:&quot;+expenses);</span>

<span class="nc" id="L183">        Properties props = new Properties();</span>
<span class="nc" id="L184">        props.put(&quot;bootstrap.servers&quot;, kafka.getBroker());</span>
<span class="nc" id="L185">        props.put(&quot;acks&quot;, &quot;all&quot;);</span>
<span class="nc" id="L186">        props.put(&quot;retries&quot;, 2);</span>
<span class="nc" id="L187">        props.put(&quot;batch.size&quot;, 16384);</span>
<span class="nc" id="L188">        props.put(&quot;linger.ms&quot;, 1);</span>
<span class="nc" id="L189">        props.put(&quot;buffer.memory&quot;, 33554432);</span>
<span class="nc" id="L190">        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span>
<span class="nc" id="L191">        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.ByteArraySerializer&quot;);</span>

<span class="nc" id="L193">        Producer&lt;String, byte[]&gt; producer = null;</span>
        try {
<span class="nc" id="L195">            producer = new KafkaProducer&lt;&gt;(props);</span>
<span class="nc" id="L196">            Schema schemaParsed = new Schema.Parser().parse(topic.getSchema());</span>

<span class="nc" id="L198">            GenericData.Record avroRecord = new GenericData.Record(schemaParsed);</span>
<span class="nc" id="L199">            avroRecord.put(&quot;customer&quot;,customer);</span>
<span class="nc" id="L200">            avroRecord.put(&quot;income&quot;,income);</span>
<span class="nc" id="L201">            avroRecord.put(&quot;expenses&quot;,expenses);</span>

<span class="nc" id="L203">            Injection&lt;GenericRecord, byte[]&gt; recordInjection = GenericAvroCodecs.toBinary(schemaParsed);</span>
<span class="nc" id="L204">            producer.send(</span>
                    new ProducerRecord&lt;String, byte[]&gt;(
                            name,
                            customer,
<span class="nc" id="L208">                            recordInjection.apply(avroRecord)</span>
                    )
            );
<span class="nc" id="L211">            result = &quot;record sent.&quot;;</span>

<span class="nc" id="L213">            Thread.sleep(250);</span>
<span class="nc" id="L214">        } catch (Exception ex) {</span>
<span class="nc" id="L215">            result =  ex.getMessage();</span>
<span class="nc" id="L216">            log.error(&quot;produceTopicRecord:Exception&quot;);</span>
<span class="nc" id="L217">            ex.printStackTrace();</span>
        } finally {
<span class="nc bnc" id="L219" title="All 6 branches missed.">            if (producer != null) {</span>
<span class="nc" id="L220">                producer.close();</span>
            }
        }

<span class="nc" id="L224">        return result;</span>
    }

    public List&lt;TopicRecord&gt; consumeTopicRecord(TypedValueMap arguments) {
<span class="nc" id="L228">        log.info(&quot;consumeTopicRecord&quot;);</span>
<span class="nc" id="L229">        List&lt;TopicRecord&gt; topicRecords = new ArrayList&lt;&gt;();</span>
<span class="nc" id="L230">        val kafka = Kafka.getInstance();</span>

<span class="nc" id="L232">        log.info(&quot;arguments&quot;+arguments.toString());</span>

<span class="nc" id="L234">        String name = arguments.get(&quot;name&quot;);</span>
<span class="nc" id="L235">        log.info(&quot;name:&quot;+name);</span>
<span class="nc" id="L236">        val topic = topics.get(name);</span>

<span class="nc" id="L238">        Properties props = new Properties();</span>
<span class="nc" id="L239">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);//latest, earliest, none</span>
<span class="nc" id="L240">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBroker());</span>
<span class="nc" id="L241">        props.put(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());</span>

<span class="nc" id="L243">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,</span>
<span class="nc" id="L244">                StringDeserializer.class.getName());</span>
<span class="nc" id="L245">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,</span>
<span class="nc" id="L246">                ByteArrayDeserializer.class.getName());</span>

<span class="nc" id="L248">        KafkaConsumer&lt;String, byte[]&gt; consumer = new KafkaConsumer&lt;&gt;(props);</span>
<span class="nc" id="L249">        consumer.subscribe(Collections.singletonList(name));</span>

<span class="nc" id="L251">        ConsumerRecords&lt;String, byte[]&gt; records = consumer.poll(500);</span>
<span class="nc bnc" id="L252" title="All 2 branches missed.">        for (ConsumerRecord&lt;String, byte[]&gt; record : records){</span>
<span class="nc" id="L253">            log.info( &quot;offset = &quot; + record.offset() +</span>
<span class="nc" id="L254">                    &quot;, key = &quot; + record.key() +</span>
<span class="nc" id="L255">                    &quot;, value = &quot; + record.value() );</span>

<span class="nc" id="L257">            GenericRecord recordConverted = parseBytes(topic.getSchema(),record.value());</span>

<span class="nc" id="L259">            log.info(&quot;{customer:&quot;+recordConverted.get(&quot;customer&quot;)</span>
<span class="nc" id="L260">                    + &quot;,income:&quot; + recordConverted.get(&quot;income&quot;)</span>
<span class="nc" id="L261">                    + &quot;,expenses:&quot; + recordConverted.get(&quot;expenses&quot;)+&quot;}&quot;);</span>

<span class="nc" id="L263">            TopicRecord topicRecord = new TopicRecord(</span>
<span class="nc" id="L264">                    record.key(), recordConverted.toString(), record.offset(), record.partition()</span>
            );
<span class="nc" id="L266">            topicRecords.add(topicRecord);</span>
<span class="nc" id="L267">        }</span>
        //consumer.commitSync();
<span class="nc" id="L269">        return topicRecords;</span>
    }

    public List&lt;TableRecord&gt; getStreamByFilter(TypedValueMap arguments) {
<span class="nc" id="L273">        log.info(&quot;getStreamByFilter&quot;);</span>
<span class="nc" id="L274">        Kafka kafka = Kafka.getInstance();</span>

<span class="nc" id="L276">        String storeKey = arguments.get(&quot;storeKey&quot;);</span>
<span class="nc" id="L277">        log.info(&quot;{storeKey:&quot;+storeKey+&quot;}&quot;);</span>

<span class="nc" id="L279">        Topic topic = topics.get(arguments.get(&quot;topic&quot;));</span>
<span class="nc" id="L280">        log.info(&quot;{topic.name:&quot;+topic.getName()+&quot;:topci.schema:&quot;+topic.getSchema()+&quot;}&quot;);</span>

<span class="nc" id="L282">        String key = arguments.get(&quot;key&quot;);</span>
<span class="nc" id="L283">        log.info(&quot;{key:&quot;+key+&quot;}&quot;);</span>

<span class="nc" id="L285">        ReadOnlyKeyValueStore&lt;String,byte[]&gt; view = streams.store(</span>
<span class="nc" id="L286">                storeKey, QueryableStoreTypes.&lt;String, byte[]&gt;keyValueStore());</span>

<span class="nc" id="L288">        KeyValueIterator&lt;String, byte[]&gt; range = view.all();</span>

<span class="nc" id="L290">        List&lt;TableRecord&gt; tableRecords = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L291" title="All 2 branches missed.">        while (range.hasNext()) {</span>
<span class="nc" id="L292">            KeyValue&lt;String, byte[]&gt; next = range.next();</span>
<span class="nc" id="L293">            log.info(&quot;table{&quot; + next.key + &quot;:&quot; + next.value+&quot;}&quot;);</span>
<span class="nc bnc" id="L294" title="All 4 branches missed.">            if( key == null || next.key.equals(key)) {</span>
<span class="nc" id="L295">                TableRecord record = new TableRecord();</span>
<span class="nc" id="L296">                record.setKey(next.key);</span>
<span class="nc" id="L297">                record.setValue(parseBytes(topic.getSchema(),next.value).toString());</span>
<span class="nc" id="L298">                tableRecords.add(record);</span>
            }
<span class="nc" id="L300">        }</span>
<span class="nc" id="L301">        return tableRecords;</span>
    }

    public List&lt;TableRecord&gt; streamStart(TypedValueMap arguments) {
<span class="nc" id="L305">        log.info(&quot;streamStart&quot;);</span>
<span class="nc" id="L306">        Kafka kafka = Kafka.getInstance();</span>
<span class="nc" id="L307">        val topicIn = topics.get(arguments.get(&quot;in&quot;));</span>
<span class="nc" id="L308">        val topicOut = topics.get(arguments.get(&quot;out&quot;));</span>
<span class="nc" id="L309">        val storeKey = (String)arguments.get(&quot;storeKey&quot;);</span>

<span class="nc" id="L311">        Properties config = new Properties();</span>
<span class="nc" id="L312">        config.put(StreamsConfig.APPLICATION_ID_CONFIG, &quot;contract-app&quot;);</span>
<span class="nc" id="L313">        config.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBroker());</span>
<span class="nc" id="L314">        config.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG,&quot;earliest&quot;);//latest, earliest, none</span>
<span class="nc" id="L315">        config.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, &quot;60000&quot;);</span>
<span class="nc" id="L316">        config.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, &quot;1000&quot;);</span>
<span class="nc" id="L317">        config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG,</span>
<span class="nc" id="L318">                Serdes.String().getClass());</span>
<span class="nc" id="L319">        config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG,</span>
<span class="nc" id="L320">                Serdes.ByteArray().getClass());</span>
<span class="nc" id="L321">        config.put(StreamsConfig.STATE_DIR_CONFIG,&quot;streams-pipe&quot;);</span>

<span class="nc" id="L323">        KStreamBuilder builder = new KStreamBuilder();</span>

<span class="nc" id="L325">        KStream&lt;String, byte[]&gt; constractStream = builder.stream(topicIn.getName());</span>


        //.peek((key, record) -&gt; log.info(&quot;mapValues:{&quot;+key+&quot;:&quot;+record.toString()+&quot;}&quot;))
<span class="nc" id="L329">        log.info(&quot;configuring stream&quot;);</span>
<span class="nc" id="L330">        KTable&lt;String, byte[]&gt; wordCounts = constractStream</span>
<span class="nc" id="L331">                .map((key, record) -&gt; {</span>
<span class="nc" id="L332">                    GenericRecord ParsedRecord = parseBytes(topicIn.getSchema(),record);</span>
<span class="nc" id="L333">                    GenericRecord newParsedRecord = parseSchema(topicOut.getSchema());</span>
<span class="nc" id="L334">                    Schema schemaParsed = new Schema.Parser().parse(topicOut.getSchema());</span>
<span class="nc" id="L335">                    newParsedRecord.put(&quot;customer&quot;,ParsedRecord.get(&quot;customer&quot;));</span>
<span class="nc" id="L336">                    newParsedRecord.put(&quot;income&quot;,ParsedRecord.get(&quot;income&quot;));</span>
<span class="nc" id="L337">                    newParsedRecord.put(&quot;expenses&quot;,ParsedRecord.get(&quot;expenses&quot;));</span>
<span class="nc" id="L338">                    newParsedRecord.put(&quot;total&quot;,</span>
<span class="nc" id="L339">                            (Integer)ParsedRecord.get(&quot;income&quot;)-</span>
<span class="nc" id="L340">                                    (Integer)ParsedRecord.get(&quot;expenses&quot;));</span>

<span class="nc" id="L342">                    Injection&lt;GenericRecord, byte[]&gt; recordInjection =</span>
<span class="nc" id="L343">                            GenericAvroCodecs.toBinary(schemaParsed);</span>
<span class="nc" id="L344">                    log.info(ParsedRecord.toString());</span>
<span class="nc" id="L345">                    log.info(newParsedRecord.toString());</span>
<span class="nc" id="L346">                    return KeyValue.pair(key,recordInjection.apply(newParsedRecord));</span>
                })
<span class="nc" id="L348">                .groupByKey()</span>
<span class="nc" id="L349">                .reduce((aggValue, newValue) -&gt; {</span>
<span class="nc" id="L350">                    GenericRecord ParsedRecord = parseBytes(topicOut.getSchema(),aggValue);</span>
<span class="nc" id="L351">                    GenericRecord ParsedNewRecord = parseBytes(topicOut.getSchema(),newValue);</span>
<span class="nc" id="L352">                    Schema schemaParsed = new Schema.Parser().parse(topicOut.getSchema());</span>
<span class="nc" id="L353">                    ParsedRecord.put(&quot;income&quot;,</span>
<span class="nc" id="L354">                            (Integer)ParsedRecord.get(&quot;income&quot;)+</span>
<span class="nc" id="L355">                                (Integer)ParsedNewRecord.get(&quot;income&quot;));</span>

<span class="nc" id="L357">                    ParsedRecord.put(&quot;expenses&quot;,</span>
<span class="nc" id="L358">                            (Integer)ParsedRecord.get(&quot;expenses&quot;)+</span>
<span class="nc" id="L359">                                    (Integer)ParsedNewRecord.get(&quot;expenses&quot;));</span>

<span class="nc" id="L361">                    ParsedRecord.put(&quot;total&quot;,</span>
<span class="nc" id="L362">                            (Integer)ParsedRecord.get(&quot;total&quot;)+</span>
<span class="nc" id="L363">                                    (Integer)ParsedNewRecord.get(&quot;total&quot;));</span>
<span class="nc" id="L364">                    log.info(ParsedRecord.toString());</span>
<span class="nc" id="L365">                    log.info(ParsedNewRecord.toString());</span>
<span class="nc" id="L366">                    Injection&lt;GenericRecord, byte[]&gt; recordInjection =</span>
<span class="nc" id="L367">                            GenericAvroCodecs.toBinary(schemaParsed);</span>
<span class="nc" id="L368">                    return recordInjection.apply(ParsedRecord);</span>
                },storeKey);

<span class="nc" id="L371">        constractStream.peek((key, value) -&gt; {</span>
<span class="nc" id="L372">            GenericRecord ParsedRecord = parseBytes(topicIn.getSchema(),value);</span>
<span class="nc" id="L373">            log.info(&quot;stream:{:&quot;+key+&quot;:&quot;+ParsedRecord.toString()+&quot;}&quot;);</span>
<span class="nc" id="L374">        });</span>

<span class="nc" id="L376">        wordCounts.filter((key, value) -&gt; {</span>
<span class="nc" id="L377">            GenericRecord ParsedRecord = parseBytes(topicOut.getSchema(),value);</span>
<span class="nc" id="L378">            log.info(&quot;table:{&quot;+key+&quot;:&quot;+ParsedRecord.toString()+&quot;}&quot;);</span>
<span class="nc" id="L379">            return true;</span>
        });

<span class="nc" id="L382">        wordCounts.to(Serdes.String(), Serdes.ByteArray(), topicOut.getName());</span>

<span class="nc" id="L384">        streams = new KafkaStreams(builder, config);</span>

        //print topology
<span class="nc" id="L387">        log.info(&quot;printing stream topology&quot;);</span>
<span class="nc" id="L388">        log.info(streams.toString());</span>

        //get queryableStoreName
<span class="nc" id="L391">        String queryableStoreName = wordCounts.queryableStoreName(); // returns null if KTable is not queryable</span>

<span class="nc" id="L393">        log.info(&quot;stream Store Name&quot;);</span>
<span class="nc" id="L394">        log.info(queryableStoreName);</span>

<span class="nc" id="L396">        log.info(&quot;Starting Stream&quot;);</span>
<span class="nc" id="L397">        streams.start();</span>

        try {
<span class="nc" id="L400">            Thread.sleep(1000L);</span>
<span class="nc" id="L401">        } catch (InterruptedException e) {</span>
<span class="nc" id="L402">            e.printStackTrace();</span>
<span class="nc" id="L403">        }</span>

<span class="nc" id="L405">        log.info(&quot;Reading Stream Value&quot;);</span>
<span class="nc" id="L406">        ReadOnlyKeyValueStore&lt;String,byte[]&gt; view = streams.store(</span>
<span class="nc" id="L407">                storeKey, QueryableStoreTypes.&lt;String, byte[]&gt;keyValueStore()</span>
        );

<span class="nc" id="L410">        KeyValueIterator&lt;String, byte[]&gt; range = view.all();</span>

<span class="nc" id="L412">        List&lt;TableRecord&gt; tableRecords = new ArrayList&lt;&gt;();</span>
<span class="nc bnc" id="L413" title="All 2 branches missed.">        while (range.hasNext()) {</span>
<span class="nc" id="L414">            KeyValue&lt;String, byte[]&gt; next = range.next();</span>
<span class="nc" id="L415">            log.info(&quot;table{&quot; + next.key + &quot;:&quot; + next.value+&quot;}&quot;);</span>
<span class="nc" id="L416">            TableRecord record = new TableRecord();</span>
<span class="nc" id="L417">            record.setKey(next.key);</span>
<span class="nc" id="L418">            record.setValue(parseBytes(topicOut.getSchema(),next.value).toString());</span>

<span class="nc" id="L420">            tableRecords.add(record);</span>
<span class="nc" id="L421">        }</span>


<span class="nc" id="L424">        Runtime.getRuntime().addShutdownHook(new Thread(streams::close));</span>

<span class="nc" id="L426">        return tableRecords;</span>
    }

    public Topic streamStop(TypedValueMap arguments) {
<span class="nc" id="L430">        log.info(&quot;streamStop&quot;);</span>
<span class="nc" id="L431">        Kafka kafka = Kafka.getInstance();</span>

<span class="nc" id="L433">        return null;</span>
    }

    public Topic updateTopic(TypedValueMap arguments) {
<span class="nc" id="L437">        log.info(&quot;updateTopic&quot;);</span>
<span class="nc" id="L438">        val topic = topics.get(arguments.get(&quot;id&quot;));</span>

<span class="nc bnc" id="L440" title="All 2 branches missed.">        if (arguments.containsKey(&quot;name&quot;)) {</span>
<span class="nc" id="L441">            topic.setName(arguments.get(&quot;name&quot;));</span>
        }

<span class="nc" id="L444">        return topic;</span>
    }

    //TODO
    public Topic deleteTopic(TypedValueMap arguments) {
<span class="nc" id="L449">        log.info(&quot;deleteTopic&quot;);</span>
<span class="nc" id="L450">        val topic = topics.get(arguments.get(&quot;id&quot;));</span>

        //topics.remove(topic.getId());

<span class="nc" id="L454">        return topic;</span>
    }

    private GenericRecord parseSchema(String schema){
<span class="nc" id="L458">        Schema schemaParsed = new Schema.Parser().parse(schema);</span>
<span class="nc" id="L459">        GenericData.Record avroRecord = new GenericData.Record(schemaParsed);</span>
<span class="nc" id="L460">        return avroRecord;</span>
    }

    private GenericRecord parseBytes(String schema, byte[] data){
<span class="nc" id="L464">        Schema schemaParsed = new Schema.Parser().parse(schema);</span>
<span class="nc" id="L465">        Injection&lt;GenericRecord, byte[]&gt; recordInjection = GenericAvroCodecs.toBinary(schemaParsed);</span>
<span class="nc" id="L466">        GenericRecord recordConverted = recordInjection.invert(data).get();</span>
<span class="nc" id="L467">        return recordConverted;</span>
    }

    //{name=contract, type=record, fields=[{name=name, type=string}, {name=income, type=int}, {name=expenses, type=int}]}
    //  },{\&quot;name\&quot;:\&quot;str2\&quot;, \&quot;type\&quot;:\&quot;string\&quot; },&quot;&quot;  { \&quot;name\&quot;:\&quot;int1\&quot;, \&quot;type\&quot;:\&quot;int\&quot; }&quot;&quot;]}&quot;;
    private String readSchema(LinkedHashMap schema){
<span class="nc" id="L473">        final StringBuilder result = new StringBuilder();</span>
<span class="nc" id="L474">        result.append(&quot;{&quot;);</span>
        //{&quot;\&quot;type\&quot;:\&quot;record\&quot;,
<span class="nc" id="L476">        result.append(doubleQuote(&quot;type&quot;,(String)schema.get(&quot;type&quot;))+&quot;,&quot;);</span>
        //&quot;\&quot;name\&quot;:\&quot;myrecord\&quot;,
<span class="nc" id="L478">        result.append(doubleQuote(&quot;name&quot;,(String)schema.get(&quot;name&quot;))+&quot;,&quot;);</span>
        //&quot;\&quot;fields\&quot;:[
<span class="nc" id="L480">        result.append(doubleQuote(&quot;fields&quot;)+&quot;:[&quot;);</span>
<span class="nc" id="L481">        ((List&lt;LinkedHashMap&gt;)schema.get(&quot;fields&quot;)).stream().forEach(</span>
                field -&gt; {
<span class="nc" id="L483">                    result.append(&quot;{&quot;);</span>
                    //{ \&quot;name\&quot;:\&quot;str1\&quot;
<span class="nc" id="L485">                    result.append(doubleQuote(&quot;name&quot;,(String)field.get(&quot;name&quot;)));</span>
                    //, \&quot;type\&quot;:\&quot;string\&quot; }
<span class="nc" id="L487">                    result.append(&quot;,&quot;);</span>
<span class="nc" id="L488">                    result.append(doubleQuote(&quot;type&quot;,(String)field.get(&quot;type&quot;)));</span>
<span class="nc" id="L489">                    result.append(&quot;},&quot;);</span>
<span class="nc" id="L490">                }</span>
        );
        // remove the last &quot;,&quot;
<span class="nc" id="L493">        result.deleteCharAt(result.length() - 1);</span>
<span class="nc" id="L494">        result.append(&quot;]}&quot;);</span>
<span class="nc" id="L495">        log.info(result.toString());</span>
<span class="nc" id="L496">        return result.toString();</span>
    }
    private String doubleQuote(String field){
<span class="nc" id="L499">        return  &quot;\&quot;&quot;+field+&quot;\&quot;&quot;;</span>
    }
    private String doubleQuote(String field, String value){
<span class="nc" id="L502">        return  &quot;\&quot;&quot;+field+&quot;\&quot;:\&quot;&quot;+value+&quot;\&quot;&quot;;</span>
    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>
<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>TopicDataFetcher.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">graphql-spring-boot-starter-sample</a> &gt; <a href="index.source.html" class="el_package">com.scigility.graphql.sample.dataFetchers</a> &gt; <span class="el_source">TopicDataFetcher.java</span></div><h1>TopicDataFetcher.java</h1><pre class="source lang-java linenums">package com.scigility.graphql.sample.dataFetchers;


import com.scigility.graphql.sample.domain.Topic;
import com.scigility.graphql.sample.domain.TopicRecord;
import com.scigility.graphql.sample.domain.Kafka;

import lombok.AllArgsConstructor;
import lombok.Getter;
import lombok.NoArgsConstructor;
import lombok.Setter;
import lombok.val;

import com.merapar.graphql.base.TypedValueMap;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.LongDeserializer;
import org.apache.kafka.common.serialization.Serdes;
import org.springframework.stereotype.Component;
import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;

import java.util.*;
import java.util.concurrent.TimeUnit;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;

import org.apache.commons.logging.Log;
import org.apache.commons.logging.LogFactory;
import org.apache.http.HttpResponse;
import org.apache.http.client.ClientProtocolException;
import org.apache.http.client.HttpClient;
import org.apache.http.client.methods.HttpPost;
import org.apache.http.client.methods.HttpGet;
import org.apache.http.entity.StringEntity;

import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.common.serialization.StringDeserializer;


import kafka.admin.AdminUtils;
import kafka.utils.ZKStringSerializer$;
import kafka.admin.RackAwareMode;
import kafka.utils.ZkUtils;

import org.I0Itec.zkclient.ZkClient;
import org.I0Itec.zkclient.ZkConnection;

import org.apache.zookeeper.ZooKeeper;

import net.sf.json.JSONArray;
import net.sf.json.JSONObject;
@Component
<span class="fc" id="L61">public class TopicDataFetcher {</span>
<span class="fc" id="L62">    private Log log = LogFactory.getLog(TopicDataFetcher.class);</span>

<span class="fc" id="L64">    public Map&lt;Integer, Topic&gt; topics = new HashMap&lt;&gt;();</span>

    public List&lt;Topic&gt; getTopicsByFilter(TypedValueMap arguments) {
<span class="nc" id="L67">        val kafka = Kafka.getInstance();</span>

<span class="nc" id="L69">        log.info(&quot;getTopicsByFilter&quot;);</span>

<span class="nc" id="L71">        ZkClient zkClient = null;</span>
<span class="nc" id="L72">        ZkUtils zkUtils = null;</span>
<span class="nc" id="L73">        int sessionTimeOutInMs = 20 * 1000; // 15 secs</span>
<span class="nc" id="L74">        int connectionTimeOutInMs = 20 * 1000; // 10 secs</span>
<span class="nc" id="L75">        boolean isSecureKafkaCluster = false;</span>

<span class="nc" id="L77">        List&lt;Topic&gt; topics = new ArrayList&lt;&gt;();</span>
        try {
<span class="nc" id="L79">            ZooKeeper zk = new ZooKeeper(</span>
<span class="nc" id="L80">                    kafka.getZookeeper(), sessionTimeOutInMs, null);</span>

<span class="nc" id="L82">            List&lt;String&gt; _topics = zk.getChildren(</span>
                    &quot;/brokers/topics&quot;, false);

            try{
<span class="nc" id="L86">                TimeUnit.MILLISECONDS.sleep((long)(sessionTimeOutInMs*0.1));</span>
<span class="nc" id="L87">            } catch (java.lang.InterruptedException e){}</span>

<span class="nc" id="L89">            log.info(&quot;List of Topics&quot;);</span>
<span class="nc" id="L90">            int index = 0;</span>
<span class="nc bnc" id="L91" title="All 2 branches missed.">            for (String topicName : _topics) {</span>
<span class="nc" id="L92">                log.info(topicName);</span>
<span class="nc" id="L93">                val topic = new Topic();</span>
<span class="nc" id="L94">                topic.setName(topicName);</span>
<span class="nc" id="L95">                topics.add(topic);</span>
<span class="nc" id="L96">            }</span>
<span class="nc" id="L97">        } catch (Exception ex) {</span>
<span class="nc" id="L98">            ex.printStackTrace();</span>
        } finally {
<span class="nc bnc" id="L100" title="All 6 branches missed.">            if (zkClient != null) {</span>
<span class="nc" id="L101">                zkClient.close();</span>
            }
        }

<span class="nc" id="L105">        return topics;</span>
    }

    public Topic addTopic(TypedValueMap arguments) {
<span class="nc" id="L109">        log.info(&quot;addTopic&quot;);</span>

        // Integer id = arguments.get(&quot;name&quot;);
        //
        // Process pr = rt.exec(&quot;kafka-topics --create --zookeeper &quot;+ zookeeperHosts +
        //   &quot; --replication-factor &quot;+noOfReplication+
        //   &quot; --partitions &quot;+noOfPartitions+
        //   &quot; --topic &quot;+topicName
        //   );
<span class="nc" id="L118">        return null;</span>
    }

    public Topic produceTopicRecord(TypedValueMap arguments) {
<span class="nc" id="L122">        log.info(&quot;produceTopicRecord&quot;);</span>
<span class="nc" id="L123">        log.info(arguments);</span>
<span class="nc" id="L124">        val kafka = Kafka.getInstance();</span>

<span class="nc" id="L126">        String name = arguments.get(&quot;name&quot;);</span>
<span class="nc" id="L127">        String message = arguments.get(&quot;message&quot;);</span>
        //log.info(arguments.get(&quot;schema&quot;));
        //LinkedHashMap schema = arguments.get(&quot;schema&quot;);

        //log.info(&quot;name:&quot;+name+&quot;,message:&quot;+message+&quot;,schema.type:&quot;+schema.get(&quot;type&quot;));
<span class="nc" id="L132">        log.info(&quot;name:&quot;+name+&quot;,message:&quot;+message);</span>
<span class="nc" id="L133">        Properties props = new Properties();</span>
<span class="nc" id="L134">        props.put(&quot;bootstrap.servers&quot;, kafka.getBroker());</span>
<span class="nc" id="L135">        props.put(&quot;acks&quot;, &quot;all&quot;);</span>
<span class="nc" id="L136">        props.put(&quot;retries&quot;, 2);</span>
<span class="nc" id="L137">        props.put(&quot;batch.size&quot;, 16384);</span>
<span class="nc" id="L138">        props.put(&quot;linger.ms&quot;, 1);</span>
<span class="nc" id="L139">        props.put(&quot;buffer.memory&quot;, 33554432);</span>
<span class="nc" id="L140">        props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span>
<span class="nc" id="L141">        props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);</span>
<span class="nc" id="L142">        Producer&lt;String, String&gt; producer = null;</span>
        try {
<span class="nc" id="L144">            producer = new KafkaProducer&lt;&gt;(props);</span>
<span class="nc" id="L145">            producer.send(new ProducerRecord&lt;String, String&gt;(name, &quot;key&quot;,message));</span>
<span class="nc" id="L146">        } catch (Exception ex) {</span>
<span class="nc" id="L147">            log.error(&quot;produceTopicRecord:Exception&quot;);</span>
<span class="nc" id="L148">            ex.printStackTrace();</span>
        } finally {
<span class="nc bnc" id="L150" title="All 6 branches missed.">            if (producer != null) {</span>
<span class="nc" id="L151">                producer.close();</span>
            }
        }

<span class="nc" id="L155">        return null;</span>
    }

    public List&lt;TopicRecord&gt; consumeTopicRecord(TypedValueMap arguments) {
<span class="nc" id="L159">        log.info(&quot;consumeTopicRecord&quot;);</span>
<span class="nc" id="L160">        log.info(arguments);</span>
<span class="nc" id="L161">        val kafka = Kafka.getInstance();</span>

<span class="nc" id="L163">        String name = arguments.get(&quot;name&quot;);</span>
<span class="nc" id="L164">        LinkedHashMap&lt;String,String&gt; schema = arguments.get(&quot;schema&quot;);</span>
<span class="nc" id="L165">        String serdeKey = schema.get(&quot;serdeKey&quot;);</span>
<span class="nc" id="L166">        String serdeValue = schema.get(&quot;serdeValue&quot;);</span>

<span class="nc" id="L168">        List&lt;TopicRecord&gt; topicRecords = new ArrayList&lt;&gt;();</span>
        //String message = arguments.get(&quot;message&quot;);
<span class="nc" id="L170">        log.info(&quot;name:&quot;+name);</span>
<span class="nc" id="L171">        log.info(&quot;serdeKey:&quot;+serdeKey);</span>
<span class="nc" id="L172">        log.info(&quot;serdeValue:&quot;+serdeValue);</span>
        //log.info(&quot;name:&quot;+name+&quot;,schema.type:&quot;+schemaType);
<span class="nc" id="L174">        Properties props = new Properties();</span>
<span class="nc" id="L175">        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);//latest, earliest, none</span>
<span class="nc" id="L176">        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafka.getBroker());</span>
<span class="nc" id="L177">        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());</span>
<span class="nc" id="L178">        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, LongDeserializer.class.getName());</span>
<span class="nc" id="L179">        props.put(ConsumerConfig.GROUP_ID_CONFIG, UUID.randomUUID().toString());</span>
//        props.put(&quot;retries&quot;, 5);
//        props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);
//        props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);
//        props.put(&quot;auto.offset.reset&quot;,);
<span class="nc" id="L184">        KafkaConsumer&lt;String, Long&gt; consumer = new KafkaConsumer&lt;&gt;(props);</span>
        //consumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));
<span class="nc" id="L186">        consumer.subscribe(Collections.singletonList(name));</span>
<span class="nc" id="L187">        ConsumerRecords&lt;String, Long&gt; records = consumer.poll(500);</span>
<span class="nc bnc" id="L188" title="All 2 branches missed.">        for (ConsumerRecord&lt;String, Long&gt; record : records){</span>
<span class="nc" id="L189">            log.info( &quot;offset = &quot; + record.offset() +</span>
<span class="nc" id="L190">                    &quot;, key = &quot; + record.key() +</span>
<span class="nc" id="L191">                    &quot;, value = &quot; + record.value() );</span>

<span class="nc" id="L193">            TopicRecord topicRecord = new TopicRecord(</span>
<span class="nc" id="L194">                    record.key(), Long.toString(record.value()), record.offset(), record.partition()</span>
            );
<span class="nc" id="L196">            topicRecords.add(topicRecord);</span>
<span class="nc" id="L197">        }</span>
        //consumer.commitSync();
<span class="nc" id="L199">        return topicRecords;</span>
    }

    public Topic updateTopic(TypedValueMap arguments) {
<span class="nc" id="L203">        log.info(&quot;updateTopic&quot;);</span>
<span class="nc" id="L204">        val topic = topics.get(arguments.get(&quot;id&quot;));</span>

<span class="nc bnc" id="L206" title="All 2 branches missed.">        if (arguments.containsKey(&quot;name&quot;)) {</span>
<span class="nc" id="L207">            topic.setName(arguments.get(&quot;name&quot;));</span>
        }

<span class="nc" id="L210">        return topic;</span>
    }

    //TODO
    public Topic deleteTopic(TypedValueMap arguments) {
<span class="nc" id="L215">        log.info(&quot;deleteTopic&quot;);</span>
<span class="nc" id="L216">        val topic = topics.get(arguments.get(&quot;id&quot;));</span>

        //topics.remove(topic.getId());

<span class="nc" id="L220">        return topic;</span>
    }
}
</pre><div class="footer"><span class="right">Created with <a href="http://www.eclemma.org/jacoco">JaCoCo</a> 0.7.7.201606060606</span></div></body></html>